{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import re\n",
    "import operator\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get all the locations in game of thrones\n",
    "response = urllib2.urlopen('http://gameofthrones.wikia.com/wiki/Category:Locations')\n",
    "html = response.read()\n",
    "linkList = (re.findall(r'\\<a href=\\\"/wiki/(.*?)\\\"\\>',html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Functions helping to clean up html code\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseurl = 'http://gameofthrones.wikia.com/wiki/'\n",
    "placeDict = {}\n",
    "\n",
    "#Looking up each of the locations\n",
    "for link in linkList:\n",
    "  html = urllib.urlopen(baseurl + link.split(\"\\\"\")[0] + '?action=edit').read()\n",
    "  text = (text_from_html(html))\n",
    "  \n",
    "  #Defining where the target text starts and ends\n",
    "  start = text.find('\\'\\'\\'')\n",
    "  end = text.find('==See also==')\n",
    "  \n",
    "  #Trimming the text to only get the relevant part\n",
    "  mainText = text[start:end]\n",
    "  mainText = re.sub('[\\[\\]\\'=\\\\n]', '', mainText)\n",
    "  mainText = re.sub('<ref>.*?</ref>', '', mainText)\n",
    "\n",
    "\n",
    "  placeDict[link] = [x.lower() for x in mainText.split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open dataset with sentiment and parse the file and save it into \n",
    "# dictiotionary in form {Word: sentiment}\n",
    "file = open('dataset1.TXT', 'r')\n",
    "\n",
    "i = 1\n",
    "senWordLitsDic = {}\n",
    "for line in file:\n",
    "    listLine = line.split()\n",
    "    if i>4:\n",
    "        senWordLitsDic[listLine[0]] = float(listLine[2])\n",
    "    i += 1\n",
    "\n",
    "# Get list of the words and calculate average sentiment using dic\n",
    "def calcAvgSentiment(tokenList, dic = senWordLitsDic):\n",
    "    suma = 0\n",
    "    nrSentimentWords = 0\n",
    "    for word in tokenList:\n",
    "        lword = word.lower()\n",
    "        # Calculate sentiment only for words \n",
    "        if lword in dic:\n",
    "            suma += dic[lword]\n",
    "            nrSentimentWords +=1\n",
    "    if nrSentimentWords == 0:\n",
    "        print \"no word has sentiment\"\n",
    "        return 0 \n",
    "    return suma/nrSentimentWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no word has sentiment\n",
      "no word has sentiment\n",
      "no word has sentiment\n",
      "no word has sentiment\n",
      "no word has sentiment\n",
      "no word has sentiment\n"
     ]
    }
   ],
   "source": [
    "#Calculating the average sentiment for all the locations\n",
    "sentimentDict = {}\n",
    "for link, val in placeDict.items():\n",
    "    sentimentDict[link] = calcAvgSentiment(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 locations with highest sentiment: \n",
      " [('Palace_of_Justice\" title=\"Palace of Justice', 5.625777777777778)\n",
      " ('Mother_of_Mountains\" title=\"Mother of Mountains', 5.588716216216221)\n",
      " ('Great_Wyk\" title=\"Great Wyk', 5.536226415094341)\n",
      " ('Moon_Pool\" title=\"Moon Pool', 5.512527472527474)\n",
      " ('Driftmark\" title=\"Driftmark', 5.506666666666666)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_sentiment = sorted(sentimentDict.items(), key=operator.itemgetter(1))\n",
    "print 'The 5 locations with highest sentiment: \\n [%s] \\n' % '\\n '.join(map(str, reversed(sorted_sentiment[-5:])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
